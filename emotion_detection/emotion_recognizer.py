import jieba
import json
import os
import re
from collections import defaultdict, Counter
import requests

category_code_to_name = {
    "127": "negemo",
    "121": "social",
    "122": "social",
    "123": "social",
    "124": "social",
    "125": "cogproc",
    "1": "i"
}

class EmotionRecognizer:
    def __init__(self, liwc_path="sc_liwc.dic"):
        self.liwc_dict = self.load_mapped_liwc(liwc_path)
        self.api_key = os.getenv("CAMELLIA_KEY")
        self.api_url = "https://api.deepseek.com/v1/chat/completions"
        self.model = "deepseek-chat"
        # === Temporarily disable EmotionRegressor related model loading to avoid errors ===
        # bert_model_path = "bert-base-chinese"
        # mlp_model = EmotionRegressor(768, 16)
        # mlp_model.load_state_dict(torch.load("emotion_detection/recognizer_training/mlp_model.pt", map_location="cpu"))
        # lgb_models = joblib.load("emotion_detection/recognizer_training/lgb_models.pkl")
        # ridge_models = joblib.load("emotion_detection/recognizer_training/ridge_models.pkl")
        # stacker = joblib.load("emotion_detection/recognizer_training/stacker.pkl")
        # self.stacking_predictor = StackingEmotionPredictor(
        #     bert_model_path, [mlp_model, lgb_models, ridge_models], stacker, max_turns=5
        # )

    def load_mapped_liwc(self, filepath, category_map=category_code_to_name):
        base_dir = os.path.dirname(os.path.abspath(__file__))
        full_path = os.path.join(base_dir, filepath)
        result = defaultdict(list)
        with open(full_path, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) < 2:
                    continue
                word = parts[0]
                codes = parts[1:]
                for code in codes:
                    if code in category_map:
                        result[category_map[code]].append(word)
        return dict(result)

    def liwc_score(self, text):
        tokens = list(jieba.cut(text, cut_all=False))
        counter = Counter()
        total = 0
        for token in tokens:
            for cat, words in self.liwc_dict.items():
                if token in words:
                    print(f"åŒ¹é…åˆ°è¯ï¼š'{token}' ç±»åˆ«ï¼š{cat}")
                    counter[cat] += 1
                    total += 1
        if total > 0:
            for k in counter:
                counter[k] = round(counter[k] / total, 2)
        return dict(counter)

    def build_windows(self, dialogue, min_rounds=5, step=2, min_words=50, max_words=150):
        windows = []
        total_utterances = len(dialogue)
        total_rounds = total_utterances // 2
        if total_rounds == 0 and total_utterances > 0:
            total_rounds = 1

        i = 0
        while i < total_rounds:
            start_idx = i * 2
            end_idx = start_idx + min_rounds * 2
            if end_idx > total_utterances:
                end_idx = total_utterances

            window_utterances = dialogue[start_idx:end_idx]
            word_count = len(list(jieba.cut(''.join(window_utterances), cut_all=False)))

            j = i + (len(window_utterances) // 2)
            while (j - i) < min_rounds and j < total_rounds:
                next_start = j * 2
                next_end = next_start + 2
                if next_end > total_utterances:
                    next_end = total_utterances
                window_utterances.extend(dialogue[next_start:next_end])
                j += 1
                word_count = len(list(jieba.cut(''.join(window_utterances), cut_all=False)))

            while word_count < min_words and j < total_rounds:
                next_start = j * 2
                next_end = next_start + 2
                if next_end > total_utterances:
                    next_end = total_utterances
                window_utterances.extend(dialogue[next_start:next_end])
                j += 1
                word_count = len(list(jieba.cut(''.join(window_utterances), cut_all=False)))

            window_text = ''.join(window_utterances)

            windows.append({
                "start_round": i,
                "end_round": j - 1,
                "num_turns": j - i,
                "num_words": word_count,
                "text": window_text
            })

            i += step

        return windows

    def analyze_windows(self, windows):
        results = []
        for win in windows:
            score = self.liwc_score(win['text'])
            results.append({
                **win,
                "score": score
            })
        return results

    def extract_json_from_markdown(self, text: str) -> str:
        match = re.search(r"```json\s*(\{.*?\})\s*```", text, re.DOTALL)
        if match:
            return match.group(1)
        return text.strip()

    def predict_emotion_stacking(self, dialogue):
        return self.stacking_predictor.predict(dialogue)

    def analyze_emotion_deepseek(self, text: str) -> dict:
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸­æ–‡æƒ…ç»ªè¯†åˆ«åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·è¾“å…¥çš„ä¸€å¥è¯ï¼Œè¯†åˆ«ä»¥ä¸‹æƒ…ç»ªå¼ºåº¦ï¼ˆèŒƒå›´ä¸º0.00 - 1.00ï¼Œä¿ç•™ä¸¤ä½å°æ•°ï¼‰ï¼š

- angerï¼ˆæ„¤æ€’ï¼‰
- sadnessï¼ˆæ‚²ä¼¤ï¼‰
- joyï¼ˆå–œæ‚¦ï¼‰
- intensityï¼ˆæ•´ä½“æƒ…ç»ªå¼ºçƒˆç¨‹åº¦ï¼‰

è¯·åªè¾“å‡ºä¸€ä¸ªJSONå¯¹è±¡ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š

{{
  "anger": 0.xx,
  "sadness": 0.xx,
  "joy": 0.xx,
  "intensity": 0.xx
}}

ç¤ºä¾‹è¾“å…¥ï¼š"æˆ‘çœŸçš„å¿«å—ä¸äº†äº†ï¼Œæ²¡äººå¬æˆ‘è¯´è¯ã€‚"

ç°åœ¨è¯·åˆ†æï¼š"{text}"
""".strip()

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": self.model,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.5
        }

        try:
            response = requests.post(self.api_url, headers=headers, json=payload, timeout=30)
            response.raise_for_status()
            content = response.json()["choices"][0]["message"]["content"]
            print("ğŸ§  DeepSeek è¿”å›ï¼š", content)

            clean_json = self.extract_json_from_markdown(content)
            return json.loads(clean_json)

        except Exception as e:
            print("âŒ æƒ…ç»ªè¯†åˆ«è°ƒç”¨å‡ºé”™ï¼š", e)
            print("ğŸ“„ åŸå§‹è¿”å›å†…å®¹:", response.text if 'response' in locals() else "No response object")
            return {"anger": 0.0, "sadness": 0.0, "joy": 0.0, "intensity": 0.0}

    def print_window_scores(self, results):
        all_categories = ["negemo", "social", "cogproc", "i"]
        for res in results:
            print(f"çª—å£ è½® {res['start_round']} - {res['end_round']}")
            print(f"è½®æ•°: {res['num_turns']}, è¯æ•°: {res['num_words']}")
            scores = res.get('score', {})
            for cat in all_categories:
                val = scores.get(cat, 0)
                print(f"  #{cat}: {val}")
            print("-" * 40)

    def analyze_rounds_liwc(self, dialogue):
        return [self.liwc_score(utt) for utt in dialogue]

    # Add judgment in all places where self.stacking_predictor is used
    def analyze_emotion(self, text):
        # Only use LLM solution, stacking_predictor not supported for now
        return self.analyze_emotion_deepseek(text)


if __name__ == "__main__":
    dialogue = [
        "æˆ‘æœ€è¿‘çœŸçš„å¾ˆç´¯ï¼Œä»€ä¹ˆéƒ½ä¸æƒ³åšã€‚",
        "ä¹Ÿä¸çŸ¥é“ï¼Œå°±æ˜¯æ¯å¤©éƒ½ä¸æƒ³èµ·åºŠã€‚",
        "èµ°ä¸åŠ¨ï¼Œæ„Ÿè§‰èº«ä½“éƒ½æ²‰é‡äº†ã€‚",
        "æ²¡æœ‰ï¼Œæˆ‘ä¸æƒ³éº»çƒ¦åˆ«äººã€‚",
        "æˆ‘å…¶å®ä¸€ç›´éƒ½è§‰å¾—å¾ˆå­¤ç‹¬ã€‚",
        "æˆ‘æ€•åˆ«äººè§‰å¾—æˆ‘å¾ˆå¥‡æ€ªã€‚",
        "æˆ‘ç»å¸¸å¤±çœ ï¼Œæ™šä¸Šè„‘å­åœä¸ä¸‹æ¥ã€‚",
        "æœ€è¿‘å¿ƒæƒ…ç‰¹åˆ«ä¸å¥½ã€‚",
        "æ¯å¤©éƒ½å¾ˆç„¦è™‘ã€‚",
        "æƒ³é€ƒé¿ä¸€åˆ‡ã€‚"
    ]

    recog = EmotionRecognizer()
    windows = recog.build_windows(dialogue)
    results = recog.analyze_windows(windows)
    recog.print_window_scores(results)

    last = dialogue[-1]
            # Only use analyze_emotion (automatic fallback)
    emotion = recog.analyze_emotion(last)
    print("\n===== DeepSeek æƒ…ç»ªè¯†åˆ«ï¼ˆæœ€è¿‘ä¸€å¥ï¼‰ =====")
    print(f"ç”¨æˆ·è¾“å…¥ï¼š{last}")
    for k, v in emotion.items():
        print(f"  {k}: {v:.2f}")
